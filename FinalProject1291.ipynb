{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmagavi/FinalProject1291/blob/main/FinalProject1291.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Project: Classifying Brain Tumors With Convolutional Neural Networks and a Foundational Model**"
      ],
      "metadata": {
        "id": "vYjQEka8xL6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing the Data**\n",
        "\n",
        "Importing the data from https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data\n",
        "\n",
        "**cjdata.label:** 1 for meningioma, 2 for glioma, 3 for pituitary tumor\n",
        "\n",
        "**cjdata.PID:** patient ID\n",
        "\n",
        "**cjdata.image:** image data\n",
        "\n",
        "**cjdata.tumorBorder:** a vector storing the coordinates of discrete points on tumor border.\n",
        "\n",
        "\t\tFor example, [x1, y1, x2, y2,...] in which x1, y1 are planar coordinates on tumor border.\n",
        "\t\tIt was generated by manually delineating the tumor border. So we can use it to generate\n",
        "\t\tbinary image of tumor mask.\n",
        "\n",
        "**cjdata.tumorMask:** a binary image with 1s indicating tumor region\n"
      ],
      "metadata": {
        "id": "yA8_ZIpwuiRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G319K8jhw0ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d719a414-0fb0-40ce-af87-0e223473f79a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atfLsK_JuaRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d7ef65-3a9c-438c-8d9d-57a7188f4cb1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p_q_wHJZQIEeinSUskvQHtqu88s2gfq8\n",
            "To: /content/brainTumorDataPublic_15332298.zip\n",
            "100% 216M/216M [00:01<00:00, 193MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EQRVW5M31GzZjEXnULygxpvBnIGOZ6WA\n",
            "To: /content/brainTumorDataPublic_22993064.zip\n",
            "100% 232M/232M [00:01<00:00, 207MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QxVOVJ89AHKQkbW-3Ftu-ajcDuzTTrIZ\n",
            "To: /content/brainTumorDataPublic_7671532.zip\n",
            "100% 218M/218M [00:02<00:00, 109MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A1dYyanURV6B7EPgI7VS-Y6tZuheEjJy\n",
            "To: /content/brainTumorDataPublic_1766.zip\n",
            "100% 214M/214M [00:01<00:00, 125MB/s]\n",
            "Archive:  brainTumorDataPublic_22993064.zip\n",
            "replace tumor_data/2299.mat? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# Importing and Downloading Images\n",
        "!gdown 1p_q_wHJZQIEeinSUskvQHtqu88s2gfq8\n",
        "!gdown 1EQRVW5M31GzZjEXnULygxpvBnIGOZ6WA\n",
        "!gdown 1QxVOVJ89AHKQkbW-3Ftu-ajcDuzTTrIZ\n",
        "!gdown 1A1dYyanURV6B7EPgI7VS-Y6tZuheEjJy\n",
        "!unzip brainTumorDataPublic_22993064.zip -d tumor_data\n",
        "!unzip brainTumorDataPublic_15332298.zip -d tumor_data\n",
        "!unzip brainTumorDataPublic_7671532.zip -d tumor_data\n",
        "!unzip brainTumorDataPublic_1766.zip -d tumor_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls tumor_data # Checking Data was loaded correctly into folder."
      ],
      "metadata": {
        "id": "8t3aG3FI3jZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG19\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [7, 7]\n",
        "plt.ion()\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchsummary import summary\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on\", device)\n",
        "\n",
        "vgg19 = models.vgg19(weights=\"IMAGENET1K_V1\").to(device)\n",
        "vgg19.eval()\n",
        "summary(vgg19, (3, 224, 224))\n"
      ],
      "metadata": {
        "id": "2XSuODeuxbof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "image_path = \"tumor_data/1571.mat\" #using one image to see model works\n",
        "\n",
        "# Open the .mat file using h5py\n",
        "with h5py.File(image_path, 'r') as file:\n",
        "    label = file['cjdata']['label'][()][0, 0]\n",
        "    patient_id = file['cjdata']['PID'][()][0, 0]\n",
        "    image_data = file['cjdata']['image'][()]\n",
        "    tumor_border = file['cjdata']['tumorBorder'][()].flatten()"
      ],
      "metadata": {
        "id": "t7ypU3hXydur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#similar code to assignment 7\n",
        "\n",
        "!gdown 13teI_njgCL6oXbGFVYrDCyhkcOYEhOtj #imagenet_classes.json\n",
        "\n",
        "def preprocess(image_data):\n",
        "    data = np.repeat(image_data[..., np.newaxis], 3, -1)\n",
        "    image = Image.fromarray((data * 255).astype(np.uint8))\n",
        "\n",
        "    # Resize and normalize using PyTorch transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    normalized_image = transform(image)\n",
        "    return normalized_image\n",
        "\n",
        "PATH_TO_LABELS = 'imagenet_classes.json'\n",
        "with open(PATH_TO_LABELS, 'r') as f:\n",
        "    imagenet_classes = json.load(f)\n",
        "\n",
        "def decode_preds(outputs, class_names=imagenet_classes):\n",
        "  # Assuming outputs is the tensor of model outputs\n",
        "  softmax_outputs = F.softmax(outputs, dim=1)\n",
        "  probability, predicted_class = torch.max(softmax_outputs, dim=1)\n",
        "\n",
        "  predicted_class_labels = [class_names[str(idx)] for idx in predicted_class.cpu().numpy()]\n",
        "  probability_scores = probability.cpu().numpy()\n",
        "\n",
        "  # Print or return the results\n",
        "  for label, score in zip(predicted_class_labels, probability_scores):\n",
        "      print(f'\\nClass: {label}, Probability: {score}')\n"
      ],
      "metadata": {
        "id": "5r052KI-0MrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = preprocess(image_data).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  vector = vgg19(array[None, :, :, :])\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image_data) #coloured by plt.imshow()\n",
        "decode_preds(vector)\n",
        "#prediction is not correct, but not crazy"
      ],
      "metadata": {
        "id": "M2TnDYmB72fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine tuning the model**"
      ],
      "metadata": {
        "id": "dgJLfljp7r9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "path = \"tumor_data\"\n",
        "file_paths = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "train_files, test_val_files = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
        "test_files, val_files = train_test_split(test_val_files, test_size=0.5, random_state=42)\n",
        "\n",
        "def move_files(file_list, destination_folder):\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "    for file in file_list:\n",
        "        shutil.move(file, destination_folder)\n",
        "\n",
        "# Move files to their folders\n",
        "move_files(train_files, \"tumor_data/train\")\n",
        "move_files(val_files, \"tumor_data/validate\")\n",
        "move_files(test_files, \"tumor_data/test\")\n"
      ],
      "metadata": {
        "id": "p4v3ArhgUAGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls tumor_data/test"
      ],
      "metadata": {
        "id": "RSpR6qYRa3Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMatDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.mat')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "\n",
        "        # Open the .mat file using h5py\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            label = file['cjdata']['label'][()][0, 0]\n",
        "            # patient_id = file['cjdata']['PID'][()][0, 0]\n",
        "            image_data = file['cjdata']['image'][()]\n",
        "            # tumor_border = file['cjdata']['tumorBorder'][()].flatten()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image_data)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train_dataset = CustomMatDataset(folder_path='tumor_data/train', transform=preprocess)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = CustomMatDataset(folder_path='tumor_data/test', transform=preprocess)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "validate_dataset = CustomMatDataset(folder_path='tumor_data/validate', transform=preprocess)\n",
        "validate_loader = DataLoader(validate_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "r7ORD8FCYaY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class names\n",
        "class_names = {\n",
        "    1: \"a\",\n",
        "    2: \"b\",\n",
        "    3: \"c\",\n",
        "}\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "ChGt127OXRgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new model for fine-tuning"
      ],
      "metadata": {
        "id": "D92csgxkUfaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_vgg19 = models.vgg19(weights=\"IMAGENET1K_V1\").to(device)\n",
        "# Freeze the layers of the standard VGG19\n",
        "for param in standard_vgg19.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the model for 5-class classification of Moth images\n",
        "# Remove the fully connected layers (classifier) on top\n",
        "standard_vgg19.classifier = nn.Identity()\n",
        "\n",
        "# Now create a new model with the features of the standard VGG19 and a new classifier\n",
        "class NewVGG19(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NewVGG19, self).__init__()\n",
        "        self.features = standard_vgg19.features\n",
        "        self.avgpool = standard_vgg19.avgpool\n",
        "        self.oldvgg = standard_vgg19\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 7 * 7, 3),  #3 classes of tumours\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.oldvgg(x)\n",
        "        print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "new_vgg19 = NewVGG19().to(device)\n",
        "print(new_vgg19)"
      ],
      "metadata": {
        "id": "Ja0DuDbMfD_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "g0OCkyzDUvIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Your code here -- #\n",
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "adam_optimizer = optim.SGD(new_vgg19.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 12\n",
        "val_accuracies = []\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for (batch_X, batch_y) in train_loader:\n",
        "      # Zero the gradients\n",
        "      # print(torch.isnan(batch_X).any(), torch.isnan(outputs).any())\n",
        "      torch.cuda.synchronize()\n",
        "      adam_optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      outputs = new_vgg19(batch_X.cuda()).float()\n",
        "      # Compute the loss\n",
        "\n",
        "      loss = criterion(outputs, batch_y.long().cuda())\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      torch.cuda.synchronize()\n",
        "      # Update weights\n",
        "      adam_optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "      print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "  new_vgg19.eval()\n",
        "  with torch.no_grad():\n",
        "    val_acc = []\n",
        "    for (batch_X, batch_y) in validate_loader:\n",
        "      val_outputs = new_vgg19(batch_X.cuda())\n",
        "      val_loss = criterion(val_outputs, batch_y.cuda())\n",
        "      _, val_preds = torch.max(val_outputs, 1)\n",
        "      val_acc.append((val_preds == batch_y.cuda()).float().mean().item())\n",
        "    val_accuracies.append(np.mean(val_acc))\n",
        "\n",
        "  print(f\"Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {np.mean(val_acc):.4f}\")\n",
        "# --------------------- #"
      ],
      "metadata": {
        "id": "LtHSnXDKfjgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}